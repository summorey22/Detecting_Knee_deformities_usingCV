{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = './train/Preprocessed/'\n",
    "temp = ['Bowlegs', 'Knock Knees', 'Normal Knee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowlegs: 111\n",
      "Knock Knees: 360\n",
      "Normal Knee: 609\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in temp:\n",
    "    for filename in os.listdir(input0 + i):\n",
    "        img = cv2.resize(cv2.imread(input0 + i + '/' + filename), (512, 512))#resize image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        fast = cv2.xfeatures2d.StarDetector_create()\n",
    "        keypoints = fast.detect(gray, None)\n",
    "        brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "        descriptors = brief.compute(gray, None)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        \n",
    "        #append to the csv file\n",
    "        csv_data=out.to_csv('./FAST/FAST_' + i + '.csv', mode='a', index=False)\n",
    "        count += 1\n",
    "    print(i + \": \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 58 fields in line 4, saw 79\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\TY-ETC\\CV\\CP\\FAST.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/TY-ETC/CV/CP/FAST.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./FAST/FAST_Bowlegs.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muint8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/TY-ETC/CV/CP/FAST.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./FAST/FAST_Knock Knees.csv\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/TY-ETC/CV/CP/FAST.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./FAST/FAST_Normal Knee.csv\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   1255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 58 fields in line 4, saw 79\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('./FAST/FAST_Bowlegs.csv', dtype='uint8')\n",
    "data2 = pd.read_csv('./FAST/FAST_Knock Knees.csv', dtype='uint8')\n",
    "data3 = pd.read_csv('./FAST/FAST_Normal Knee.csv', dtype='uint8')\n",
    "\n",
    "data1 = data1.astype('uint8')\n",
    "data2 = data2.astype('uint8')\n",
    "data3 = data3.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on each class\n",
    "#Bowlegs\n",
    "kmeans1 = KMeans(n_clusters=5)\n",
    "kmeans1.fit(data1)\n",
    "\n",
    "#Knock Knees\n",
    "kmeans2 = KMeans(n_clusters=5)\n",
    "kmeans2.fit(data2)\n",
    "\n",
    "#Normal\n",
    "kmeans3 = KMeans(n_clusters=5)\n",
    "kmeans3.fit(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of bowed\n",
      "(array([3714, 2468, 3072, 4192, 4394], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n",
      "histogram of knocked\n",
      "(array([17271, 14975,  7585,  5175, 24516], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n",
      "histogram of normal\n",
      "(array([14837, 11392, 19722,  7531, 11596], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist1=np.histogram(kmeans1.labels_,bins=[0,1,2,3,4,5])\n",
    "hist2=np.histogram(kmeans2.labels_,bins=[0,1,2,3,4,5])\n",
    "hist3=np.histogram(kmeans3.labels_,bins=[0,1,2,3,4,5])\n",
    "\n",
    "print('histogram of bowed')\n",
    "print(hist1,\"\\n\")\n",
    "\n",
    "print('histogram of knocked')\n",
    "print(hist2,\"\\n\")\n",
    "\n",
    "print('histogram of normal')\n",
    "print(hist3,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire apple dataset with the pretrained kmeans model\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "for j in temp:\n",
    "    data=[]\n",
    "    for filename in os.listdir(input0 + j):\n",
    "        path = input0 + j + '/' + filename\n",
    "        a=cv2.imread(path)\n",
    "        resize=(512,512)\n",
    "        img=cv2.resize(a,resize)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        \n",
    "        array_double = np.array(out, dtype=np.double)\n",
    "\n",
    "        a=kmeans1.predict(array_double)\n",
    "        hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "        #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "        data.append(hist[0])\n",
    "    \n",
    "    #convert Array to Dataframe and append to the list\n",
    "    Output = pd.DataFrame(data)\n",
    "    #add row class \n",
    "    Output[\"Class\"] = i \n",
    "    csv_data=Output.to_csv('./SIFT/SIFT_'+ j + 'Final.csv', mode='a', index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4  Class\n",
      "0     4   3   2  24   5      0\n",
      "1     5   8   1  18   3      0\n",
      "2     6   8  34  28  15      0\n",
      "3    14  38  52  60  39      0\n",
      "4     8  41  39  69  33      0\n",
      "..   ..  ..  ..  ..  ..    ...\n",
      "244  37  28   5  30  11      2\n",
      "245   7   4  16  16   1      2\n",
      "246   9   4  18  18   2      2\n",
      "247  12   5  23  15   1      2\n",
      "248  16   8  20  21   6      2\n",
      "\n",
      "[609 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_7652\\555719870.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp1 = final.append(pd.read_csv('./SIFT/SIFT_Knock KneesFinal.csv'))\n",
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_7652\\555719870.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tcc = temp1.append(tc)\n"
     ]
    }
   ],
   "source": [
    "final = pd.read_csv('./SIFT/SIFT_BowlegsFinal.csv')\n",
    "temp1 = final.append(pd.read_csv('./SIFT/SIFT_Knock KneesFinal.csv'))\n",
    "tc = pd.read_csv('./SIFT/SIFT_Normal KneeFinal.csv')\n",
    "tcc = temp1.append(tc)\n",
    "csv_data = tcc.to_csv('./SIFT/SIFT_FeatureFinal.csv', mode='a', index=False)\n",
    "print(tcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./SIFT/SIFT_FeatureFinal.csv')\n",
    "X_train = df.iloc[:, 0:5]\n",
    "Y_train = df.iloc[:, 5:6]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X_train, Y_train, \n",
    "                                                      test_size=0.5, \n",
    "                                                      stratify=Y_train, \n",
    "                                                      random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "  \n",
    "knn.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for KNN\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.7171052631578947\n",
      "Precision:  0.689380972757096\n",
      "Recall:  0.6774193548387096\n",
      "F-score:  0.6820155747044955\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.5672131147540984\n",
      "Precision:  0.5270189986118522\n",
      "Recall:  0.5258181818181819\n",
      "F-score:  0.5253049361539928\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for KNN')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = knn.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = knn.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for XgBoost\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F-score:  1.0\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.6426229508196721\n",
      "Precision:  0.6093477373129895\n",
      "Recall:  0.5837575757575758\n",
      "F-score:  0.5891450433469241\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for XgBoost')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsOneClassifier(estimator=SVC())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "subclassifier = SVC(kernel='rbf')\n",
    "classifier = OneVsOneClassifier(estimator=subclassifier)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for SVM\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.5789473684210527\n",
      "Precision:  0.3856209150326797\n",
      "Recall:  0.4731182795698925\n",
      "F-score:  0.423744292237443\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.5377049180327869\n",
      "Precision:  0.3600370762711864\n",
      "Recall:  0.4373333333333333\n",
      "F-score:  0.3923862872898289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for SVM')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for Naive Bayes\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.4144736842105263\n",
      "Precision:  0.4701986754966887\n",
      "Recall:  0.3387096774193548\n",
      "F-score:  0.2046352187197258\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.4163934426229508\n",
      "Precision:  0.3873200442967885\n",
      "Recall:  0.33866666666666667\n",
      "F-score:  0.2095570841067074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for Naive Bayes')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e11265db24d7d7b1d9a614b6c8aed899b36881c20eb26f07e2c77f204b3164ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
