{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_augmented_dataset = \"F:\\\\2022-2023\\\\SEM 1\\\\CV\\\\Dataset_1\\\\Augmented\\\\\"\n",
    "temp = ['Bowlegs', 'Knock-knee', 'Normal Knee']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "c = 0\n",
    "for i in temp:\n",
    "    path_to_folder = path_to_augmented_dataset+i\n",
    "    for fname in os.listdir(path_to_folder):\n",
    "        path_to_file = path_to_folder+\"\\\\\"+fname\n",
    "        img = cv2.imread(path_to_file)\n",
    "        cell_size = (32, 32)  # h x w in pixels\n",
    "        block_size = (2, 2)  # h x w in cells\n",
    "        nbins = 9  # number of orientation bins\n",
    "        hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "        descriptor = hog.compute(img)\n",
    "\n",
    "        out1 = pd.DataFrame(descriptor)\n",
    "        csv_data = out1.to_csv(r'HOG\\HOG_{}.csv'.format(i), mode='a', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # print(data)\n",
    "    return data.astype(np.float64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p0 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_Bowlegs.csv'\n",
    "p1 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_Knock-knee.csv'\n",
    "p2 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_Normal Knee.csv'\n",
    "pf = 'HOG\\HOG_FINAL.csv'\n",
    "\n",
    "data1 = data_f = read_data(p0)\n",
    "print(data1.shape)\n",
    "data2 = read_data(p1)\n",
    "print(data2.shape)\n",
    "data3 = read_data(p2)\n",
    "print(data3.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(data1)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), inertias, marker='o')\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#performing kmeans on each class\n",
    "\n",
    "kmeans1 = KMeans(n_clusters=6)\n",
    "kmeans1.fit(data1)\n",
    "\n",
    "kmeans2 = KMeans(n_clusters=6)\n",
    "kmeans2.fit(data2)\n",
    "\n",
    "kmeans3 = KMeans(n_clusters=6)\n",
    "kmeans3.fit(data3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"HOG_model1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kmeans1, f)\n",
    "with open(\"HOG_model2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kmeans2, f)\n",
    "with open(\"HOG_model3.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kmeans3, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "c = 0\n",
    "for i in temp:\n",
    "    data = []\n",
    "    path_to_folder = path_to_augmented_dataset+i\n",
    "    for fname in os.listdir(path_to_folder):\n",
    "        path_to_file = path_to_folder+\"\\\\\"+fname\n",
    "        img = cv2.imread(path_to_file)\n",
    "        cell_size = (32, 32)  # h x w in pixels\n",
    "        block_size = (2, 2)  # h x w in cells\n",
    "        nbins = 9  # number of orientation bins\n",
    "        hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "        descriptor = hog.compute(img)\n",
    "        out1 = pd.DataFrame(descriptor)\n",
    "        array_double = np.array(out1, dtype=np.double)\n",
    "        if i == temp[0]:\n",
    "            a=kmeans1.predict(array_double)\n",
    "        elif i == temp[1]:\n",
    "            a = kmeans2.predict(array_double)\n",
    "        else:\n",
    "            a = kmeans3.predict(array_double)\n",
    "        hist=np.histogram(a,bins=6)\n",
    "        print(\"HIST DATA\", hist)\n",
    "\n",
    "        data.append(hist[0])\n",
    "    Output = pd.DataFrame(data)\n",
    "    Output[\"Class\"] = c\n",
    "    csv_data=Output.to_csv(r'HOG\\HOG_FINAL_{}.csv'.format(i), mode='a', index=False)\n",
    "    c += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pf0 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_FINAL_Bowlegs.csv'\n",
    "pf1 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_FINAL_Knock-knee.csv'\n",
    "pf2 = r'F:\\2022-2023\\SEM 1\\CV\\CV_FINAL\\HOG\\HOG_FINAL_Normal Knee.csv'\n",
    "pfd = 'HOG\\HOG_FINAL.csv'\n",
    "d1 = fd = read_data(pf0)\n",
    "print(d1)\n",
    "d2 = read_data(pf1)\n",
    "print(d2)\n",
    "d3 = read_data(pf2)\n",
    "print(d3)\n",
    "fd = fd.append(d2)\n",
    "fd = fd.append(d3)\n",
    "print(fd)\n",
    "csv_data = fd.to_csv(pfd, mode='a', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = read_data(pfd)\n",
    "X = data.iloc[:, :-1]\n",
    "print(X)\n",
    "Y = data.iloc[:, -1]\n",
    "print(Y)\n",
    "\n",
    "# train test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, train_size=0.8)\n",
    "print(train_X)\n",
    "print(test_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 7))\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# # adding major gridlines\n",
    "# ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "# ax.scatter(train_X, train_Y, color=\"#8C7298\")\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_X_KNN = sc.fit_transform(train_X)\n",
    "test_X_KNN = sc.transform(test_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.fit(train_X_KNN, train_Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test_X_KNN)\n",
    "\n",
    "cm = confusion_matrix(test_Y, y_pred)\n",
    "ac = accuracy_score(test_Y,y_pred)\n",
    "print(cm)\n",
    "print(ac)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XgBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = XGBClassifier()\n",
    "sc = StandardScaler()\n",
    "train_X = sc.fit_transform(train_X)\n",
    "test_X = sc.transform(test_X)\n",
    "model.fit(train_X, train_Y)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(test_X)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(test_Y, y_pred)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "classifier_SVM = SVC(kernel='linear')\n",
    "# classifier_SVM = SVC(kernel='sigmoid')\n",
    "# classifier_SVM = SVC(kernel='linear')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier_SVM.fit(train_X, train_Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = classifier_SVM.predict(test_X)\n",
    "cm = confusion_matrix(test_Y, predictions)\n",
    "ac = accuracy_score(test_Y,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cm, ac)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
