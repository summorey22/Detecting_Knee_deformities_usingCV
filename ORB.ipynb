{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = './train/Preprocessed/'\n",
    "temp = ['Bowlegs', 'Knock Knees', 'Normal Knee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowlegs: 111\n",
      "Knock Knees: 360\n",
      "Normal Knee: 609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for i in temp:\n",
    "    for filename in os.listdir(input0 + i):\n",
    "        img = cv2.resize(cv2.imread(input0 + i + '/' + filename), (512, 512))#resize image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "\n",
    "        orb_image = cv2.drawKeypoints(gray, keypoints, img)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        #append to the csv file\n",
    "        csv_data=out.to_csv('./ORB/ORB_' + i + '.csv', mode='a', index=False)\n",
    "        count += 1\n",
    "    print(i + \": \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./ORB/ORB_Bowlegs.csv', dtype='uint8')\n",
    "data2 = pd.read_csv('./ORB/ORB_Knock Knees.csv', dtype='uint8')\n",
    "data3 = pd.read_csv('./ORB/ORB_Normal Knee.csv', dtype='uint8')\n",
    "\n",
    "data1 = data1.astype('uint8')\n",
    "data2 = data2.astype('uint8')\n",
    "data3 = data3.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on each class\n",
    "#Bowlegs\n",
    "kmeans1 = KMeans(n_clusters=5)\n",
    "kmeans1.fit(data1)\n",
    "\n",
    "#Knock Knees\n",
    "kmeans2 = KMeans(n_clusters=5)\n",
    "kmeans2.fit(data2)\n",
    "\n",
    "#Normal\n",
    "kmeans3 = KMeans(n_clusters=5)\n",
    "kmeans3.fit(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of bowed\n",
      "(array([4155, 4520, 4919, 4843, 4566], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n",
      "histogram of knocked\n",
      "(array([11872, 12939, 13349, 10295, 10564], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n",
      "histogram of normal\n",
      "(array([12201, 10778, 14383, 13048, 14589], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist1=np.histogram(kmeans1.labels_,bins=[0,1,2,3,4,5])\n",
    "hist2=np.histogram(kmeans2.labels_,bins=[0,1,2,3,4,5])\n",
    "hist3=np.histogram(kmeans3.labels_,bins=[0,1,2,3,4,5])\n",
    "\n",
    "print('histogram of bowed')\n",
    "print(hist1,\"\\n\")\n",
    "\n",
    "print('histogram of knocked')\n",
    "print(hist2,\"\\n\")\n",
    "\n",
    "print('histogram of normal')\n",
    "print(hist3,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire apple dataset with the pretrained kmeans model\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "count = 0\n",
    "for j in temp:\n",
    "    data=[]\n",
    "    for filename in os.listdir(input0 + j):\n",
    "        path = input0 + j + '/' + filename\n",
    "        a=cv2.imread(path)\n",
    "        resize=(512,512)\n",
    "        img=cv2.resize(a,resize)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        \n",
    "        #predict values of feature vector with pretrained kmeans\n",
    "        #ValueError: Buffer dtype mismatch, expected 'float' but got 'double', in order to avoid this dtype=np.double\n",
    "        array_double = np.array(out, dtype=np.double)\n",
    "        if(array_double.shape == (0, 0)): continue\n",
    "\n",
    "        a=kmeans1.predict(array_double)\n",
    "        hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "        #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "        data.append(hist[0])\n",
    "    \n",
    "    #convert Array to Dataframe and append to the list\n",
    "    Output = pd.DataFrame(data)\n",
    "    #add row class \n",
    "    Output[\"Class\"] = i \n",
    "    csv_data=Output.to_csv('./ORB/ORB_'+ j + 'Final.csv', mode='a', index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2    3    4  Class\n",
      "0    18  20   3    2    6      0\n",
      "1    12  19   2    7   19      0\n",
      "2    26  37  28    4    1      0\n",
      "3    37  45  31  141  117      0\n",
      "4    48  30  46  131  106      0\n",
      "..   ..  ..  ..  ...  ...    ...\n",
      "241  79  41  24   28    5      2\n",
      "242   8   5   1    3    2      2\n",
      "243   7   4   2    2    2      2\n",
      "244   9   7   2    3    3      2\n",
      "245  28  40  29    6    7      2\n",
      "\n",
      "[605 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_18912\\356897624.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp1 = final.append(pd.read_csv('./ORB/ORB_Knock KneesFinal.csv'))\n",
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_18912\\356897624.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tcc = temp1.append(tc)\n"
     ]
    }
   ],
   "source": [
    "final = pd.read_csv('./ORB/ORB_BowlegsFinal.csv')\n",
    "temp1 = final.append(pd.read_csv('./ORB/ORB_Knock KneesFinal.csv'))\n",
    "tc = pd.read_csv('./ORB/ORB_Normal KneeFinal.csv')\n",
    "tcc = temp1.append(tc)\n",
    "csv_data = tcc.to_csv('./ORB/ORB_FeatureFinal.csv', mode='a', index=False)\n",
    "print(tcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ORB/ORB_FeatureFinal.csv')\n",
    "X_train = df.iloc[:, 0:5]\n",
    "Y_train = df.iloc[:, 5:6]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X_train, Y_train, \n",
    "                                                      test_size=0.5, \n",
    "                                                      stratify=Y_train, \n",
    "                                                      random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "  \n",
    "knn.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for KNN\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.6854304635761589\n",
      "Precision:  0.6541992229841803\n",
      "Recall:  0.62926153748341\n",
      "F-score:  0.6358607506282701\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.5115511551155115\n",
      "Precision:  0.484672619047619\n",
      "Recall:  0.4638954454060669\n",
      "F-score:  0.4677800066246281\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for KNN')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = knn.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = knn.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:29:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for XgBoost\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F-score:  1.0\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.5775577557755776\n",
      "Precision:  0.5365236864771749\n",
      "Recall:  0.527757483796036\n",
      "F-score:  0.5296582147240595\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for XgBoost')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsOneClassifier(estimator=SVC())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "subclassifier = SVC(kernel='rbf')\n",
    "classifier = OneVsOneClassifier(estimator=subclassifier)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for SVM\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.6059602649006622\n",
      "Precision:  0.411020692862125\n",
      "Recall:  0.4942739749978145\n",
      "F-score:  0.44210194808116254\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.504950495049505\n",
      "Precision:  0.33654548776032156\n",
      "Recall:  0.4133228429058484\n",
      "F-score:  0.3665634508920792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for SVM')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for Naive Bayes\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.46688741721854304\n",
      "Precision:  0.5302847247392372\n",
      "Recall:  0.3862142272449118\n",
      "F-score:  0.3120775073612215\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.41254125412541254\n",
      "Precision:  0.40314575506644895\n",
      "Recall:  0.34285589399672795\n",
      "F-score:  0.2682887030978634\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for Naive Bayes')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e11265db24d7d7b1d9a614b6c8aed899b36881c20eb26f07e2c77f204b3164ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
