{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = './Dataset/Augmented/'\n",
    "temp = ['Bowlegs', 'Knock-knee', 'Normal Knee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowlegs: 961\n",
      "Knock-knee: 1944\n",
      "Normal Knee: 2902\n"
     ]
    }
   ],
   "source": [
    "for i in temp:\n",
    "    count = 0\n",
    "    for filename in os.listdir(input0 + i):\n",
    "        img = cv2.imread(input0 + i + '/' + filename)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "        sift_image = cv2.drawKeypoints(gray, keypoints, img)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        \n",
    "        #append to the csv file\n",
    "        \n",
    "        csv_data=out.to_csv('./SIFT/SIFT_' + i + '.csv', mode='a', index=False)\n",
    "        count += 1\n",
    "    print(i + \": \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\FinalData.csv', dtype='uint8')\n",
    "data2 = pd.read_csv('./SIFT/SIFT_Knock-knee.csv', dtype='uint8')\n",
    "data3 = pd.read_csv('./SIFT/SIFT_Normal Knee.csv', dtype='uint8')\n",
    "\n",
    "\n",
    "data1 = data1.astype('uint8')\n",
    "data2 = data2.astype('uint8')\n",
    "data3 = data3.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Knock Knees\\nkmeans2 = KMeans(n_clusters=5)\\nkmeans2.fit(data2)\\n\\n#Normal\\nkmeans3 = KMeans(n_clusters=5)\\nkmeans3.fit(data3)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on each class\n",
    "#Bowlegs\n",
    "kmeans1 = KMeans(n_clusters=2)\n",
    "kmeans1.fit(data1)\n",
    "\n",
    "\"\"\"#Knock Knees\n",
    "kmeans2 = KMeans(n_clusters=5)\n",
    "kmeans2.fit(data2)\n",
    "\n",
    "#Normal\n",
    "kmeans3 = KMeans(n_clusters=5)\n",
    "kmeans3.fit(data3)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of bowed\n",
      "(array([114625,  88210,      0,      0,      0], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\\'histogram of knocked\\')\\nprint(hist2,\"\\n\")\\n\\nprint(\\'histogram of normal\\')\\nprint(hist3,\"\\n\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist1=np.histogram(kmeans1.labels_,bins=[0,1,2,3,4,5])\n",
    "\"\"\"hist2=np.histogram(kmeans2.labels_,bins=[0,1,2,3,4,5])\n",
    "hist3=np.histogram(kmeans3.labels_,bins=[0,1,2,3,4,5])\"\"\"\n",
    "\n",
    "print('histogram of bowed')\n",
    "print(hist1,\"\\n\")\n",
    "\n",
    "\"\"\"print('histogram of knocked')\n",
    "print(hist2,\"\\n\")\n",
    "\n",
    "print('histogram of normal')\n",
    "print(hist3,\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire apple dataset with the pretrained kmeans model\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "for j in temp:\n",
    "    data=[]\n",
    "    for filename in os.listdir(input0 + j):\n",
    "        path = input0 + j + '/' + filename\n",
    "        a=cv2.imread(path)\n",
    "        gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #initialise sift descriptor\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        #convert the descriptor array into a dataframe format\n",
    "        out=pd.DataFrame(descriptors)\n",
    "        \n",
    "        #predict values of feature vector with pretrained kmeans\n",
    "        #ValueError: Buffer dtype mismatch, expected 'float' but got 'double', in order to avoid this dtype=np.double\n",
    "        array_double = np.array(out, dtype=np.double)\n",
    "\n",
    "        a=kmeans1.predict(array_double)\n",
    "        hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "        #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "        data.append(hist[0])\n",
    "    \n",
    "    #convert Array to Dataframe and append to the list\n",
    "    Output = pd.DataFrame(data)\n",
    "    #add row class \n",
    "    Output[\"Class\"] = i \n",
    "    csv_data=Output.to_csv('./SIFT/SIFTH_'+ j + 'Final.csv', mode='a', index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1  2  3  4  Class\n",
      "0    57   90  0  0  0      0\n",
      "1    49  110  0  0  0      0\n",
      "2    47  106  0  0  0      0\n",
      "3    12    3  0  0  0      0\n",
      "4    58   46  0  0  0      0\n",
      "..   ..  ... .. .. ..    ...\n",
      "953   5    4  0  0  0      2\n",
      "954  45  175  0  0  0      2\n",
      "955  50   21  0  0  0      2\n",
      "956  39   13  0  0  0      2\n",
      "957  48   16  0  0  0      2\n",
      "\n",
      "[2902 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_10636\\3256986680.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp1 = final.append(pd.read_csv('./SIFT/SIFT_Knock-kneeFinal.csv'))\n",
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_10636\\3256986680.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tcc = temp1.append(tc)\n"
     ]
    }
   ],
   "source": [
    "final = pd.read_csv('./SIFT/SIFT_BowlegsFinal.csv')\n",
    "temp1 = final.append(pd.read_csv('./SIFT/SIFT_Knock-kneeFinal.csv'))\n",
    "tc = pd.read_csv('./SIFT/SIFT_Normal KneeFinal.csv')\n",
    "tcc = temp1.append(tc)\n",
    "csv_data = tcc.to_csv('./SIFT/SIFTH_FeatureFinal.csv', mode='a', index=False)\n",
    "print(tcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./SIFT/SIFTH_FeatureFinal.csv')\n",
    "X_train = df.iloc[:, 0:5]\n",
    "Y_train = df.iloc[:, 5:6]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X_train, Y_train, \n",
    "                                                      test_size=0.3, \n",
    "                                                      stratify=Y_train, \n",
    "                                                      random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "  \n",
    "knn.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for KNN\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.5307730182176268\n",
      "Precision:  0.5313210527222668\n",
      "Recall:  0.5304664176955508\n",
      "F-score:  0.5306382948518115\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.45120551090700345\n",
      "Precision:  0.45528899276567464\n",
      "Recall:  0.45134573132454486\n",
      "F-score:  0.452435424345428\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for KNN')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = knn.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = knn.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:33:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for XgBoost\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.604628261939931\n",
      "Precision:  0.6049470021307489\n",
      "Recall:  0.6042148272425494\n",
      "F-score:  0.6020343903273256\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.4362801377726751\n",
      "Precision:  0.43168300611458904\n",
      "Recall:  0.4357501569365976\n",
      "F-score:  0.4318509282811958\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for XgBoost')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsOneClassifier(estimator=SVC())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "subclassifier = SVC(kernel='rbf')\n",
    "classifier = OneVsOneClassifier(estimator=subclassifier)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for SVM\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.4775972427375677\n",
      "Precision:  0.4781223718449381\n",
      "Recall:  0.4772281599707328\n",
      "F-score:  0.4772341604415442\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.45120551090700345\n",
      "Precision:  0.45399112397844044\n",
      "Recall:  0.4509063088512241\n",
      "F-score:  0.4519475480854858\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for SVM')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results obtained for Naive Bayes\n",
      "\n",
      "Results obtained on Training Data\n",
      "Accuracy on Train data :  0.4155588380108321\n",
      "Precision:  0.4426633400284592\n",
      "Recall:  0.41283579166952483\n",
      "F-score:  0.38350697126628047\n",
      "\n",
      "Results obtained on Testing Data\n",
      "Accuracy on Test data :  0.4087256027554535\n",
      "Precision:  0.41049536905405715\n",
      "Recall:  0.4062421531701193\n",
      "F-score:  0.3735772005059195\n"
     ]
    }
   ],
   "source": [
    "print('\\nResults obtained for Naive Bayes')\n",
    "\n",
    "# accuracy on training data\n",
    "y_pred_t = classifier.predict(train_x)\n",
    "train_data_accuracy = accuracy_score(y_pred_t, train_y)\n",
    "\n",
    "print('\\nResults obtained on Training Data')\n",
    "print('Accuracy on Train data : ', train_data_accuracy)\n",
    "print(\"Precision: \", precision_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"Recall: \", recall_score(train_y, y_pred_t, average='macro'))\n",
    "print(\"F-score: \", f1_score(train_y, y_pred_t, average='macro'))\n",
    "\n",
    "# Accuracy on test data\n",
    "y_pred_ts = classifier.predict(valid_x)\n",
    "test_data_accuracy = accuracy_score(y_pred_ts, valid_y)\n",
    "\n",
    "print('\\nResults obtained on Testing Data')\n",
    "print('Accuracy on Test data : ', test_data_accuracy)\n",
    "print(\"Precision: \", precision_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"Recall: \", recall_score(valid_y, y_pred_ts, average='macro'))\n",
    "print(\"F-score: \", f1_score(valid_y, y_pred_ts, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e11265db24d7d7b1d9a614b6c8aed899b36881c20eb26f07e2c77f204b3164ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
